#!/usr/bin/env python3
"""
NYC Event Finder
æ¯å‘¨è‡ªåŠ¨æœç´¢çº½çº¦å¸‚çš„æ´»åŠ¨å¹¶å‘é€é‚®ä»¶é€šçŸ¥

æ•°æ®æ¥æº:
- Luma (lu.ma) - Tech/Startup æ´»åŠ¨
- Eventbrite embed widget - å…¬å¼€æ´»åŠ¨
"""

import os
import re
import json
import requests
from datetime import datetime, timedelta
from typing import List, Dict, Any
from bs4 import BeautifulSoup

# æœç´¢é…ç½®
LOCATION = "New York"
SEARCH_KEYWORDS = ["tech", "startup", "design", "networking", "AI", "creative"]
DAYS_AHEAD = 14


def get_luma_events() -> List[Dict[str, Any]]:
    """ä» Luma è·å–çº½çº¦çš„æ´»åŠ¨"""
    events = []

    # Luma NYC discover page
    urls = [
        "https://lu.ma/nyc",
        "https://lu.ma/discover?city=New%20York",
    ]

    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36"
    }

    for url in urls:
        try:
            response = requests.get(url, headers=headers, timeout=30)
            if response.status_code != 200:
                continue

            # å°è¯•ä»é¡µé¢æå– JSON æ•°æ®
            soup = BeautifulSoup(response.text, 'html.parser')

            # æŸ¥æ‰¾ script æ ‡ç­¾ä¸­çš„äº‹ä»¶æ•°æ®
            scripts = soup.find_all('script')
            for script in scripts:
                if script.string and 'events' in script.string.lower():
                    # å°è¯•æå– JSON
                    try:
                        # æŸ¥æ‰¾ JSON å¯¹è±¡
                        matches = re.findall(r'\{[^{}]*"name"[^{}]*"start_at"[^{}]*\}', script.string)
                        for match in matches:
                            try:
                                event_data = json.loads(match)
                                events.append({
                                    "name": event_data.get("name", ""),
                                    "start": event_data.get("start_at", ""),
                                    "url": event_data.get("url", ""),
                                    "location": event_data.get("geo_address_info", {}).get("full_address", "New York"),
                                    "source": "Luma"
                                })
                            except json.JSONDecodeError:
                                continue
                    except Exception:
                        continue

            # å¤‡ç”¨æ–¹æ¡ˆ: ä» HTML æå–æ´»åŠ¨é“¾æ¥
            event_links = soup.find_all('a', href=re.compile(r'lu\.ma/[a-zA-Z0-9]+'))
            for link in event_links[:20]:  # é™åˆ¶æ•°é‡
                href = link.get('href', '')
                if href and 'lu.ma' in href:
                    events.append({
                        "name": link.get_text(strip=True) or "Luma Event",
                        "start": "",
                        "url": href if href.startswith('http') else f"https://lu.ma{href}",
                        "location": "New York",
                        "source": "Luma"
                    })

        except Exception as e:
            print(f"Error fetching Luma events from {url}: {e}")

    return events


def get_eventbrite_events() -> List[Dict[str, Any]]:
    """ä» Eventbrite å…¬å¼€é¡µé¢è·å–æ´»åŠ¨"""
    events = []

    # Eventbrite NYC å…¬å¼€æœç´¢é¡µé¢
    base_url = "https://www.eventbrite.com/d/ny--new-york"

    search_urls = [
        f"{base_url}/tech/",
        f"{base_url}/startup/",
        f"{base_url}/networking/",
        f"{base_url}/business/",
    ]

    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
    }

    for url in search_urls:
        try:
            response = requests.get(url, headers=headers, timeout=30)
            if response.status_code != 200:
                continue

            soup = BeautifulSoup(response.text, 'html.parser')

            # æŸ¥æ‰¾æ´»åŠ¨å¡ç‰‡
            event_cards = soup.find_all('div', {'data-testid': re.compile(r'event-card')})
            if not event_cards:
                event_cards = soup.find_all('article')
            if not event_cards:
                event_cards = soup.find_all('div', class_=re.compile(r'event'))

            for card in event_cards[:15]:
                try:
                    # æå–æ´»åŠ¨åç§°
                    title_elem = card.find(['h2', 'h3', 'a'])
                    name = title_elem.get_text(strip=True) if title_elem else ""

                    # æå–é“¾æ¥
                    link = card.find('a', href=True)
                    event_url = link['href'] if link else ""
                    if event_url and not event_url.startswith('http'):
                        event_url = f"https://www.eventbrite.com{event_url}"

                    # æå–æ—¥æœŸ
                    date_elem = card.find(['time', 'span'], class_=re.compile(r'date|time'))
                    date_str = date_elem.get_text(strip=True) if date_elem else ""

                    # æå–åœ°ç‚¹
                    location_elem = card.find(['span', 'p'], class_=re.compile(r'location|venue'))
                    location = location_elem.get_text(strip=True) if location_elem else "New York"

                    if name and event_url:
                        events.append({
                            "name": name,
                            "start": date_str,
                            "url": event_url,
                            "location": location,
                            "source": "Eventbrite"
                        })
                except Exception:
                    continue

        except Exception as e:
            print(f"Error fetching Eventbrite events from {url}: {e}")

    return events


def get_meetup_events() -> List[Dict[str, Any]]:
    """ä» Meetup è·å–æ´»åŠ¨"""
    events = []

    # Meetup NYC tech groups
    urls = [
        "https://www.meetup.com/find/?location=us--ny--New%20York&source=EVENTS&keywords=tech",
        "https://www.meetup.com/find/?location=us--ny--New%20York&source=EVENTS&keywords=startup",
    ]

    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36"
    }

    for url in urls:
        try:
            response = requests.get(url, headers=headers, timeout=30)
            if response.status_code != 200:
                continue

            soup = BeautifulSoup(response.text, 'html.parser')

            # æŸ¥æ‰¾æ´»åŠ¨é“¾æ¥
            event_links = soup.find_all('a', href=re.compile(r'meetup\.com/.*/events/'))

            for link in event_links[:15]:
                href = link.get('href', '')
                name = link.get_text(strip=True)

                if name and href:
                    events.append({
                        "name": name,
                        "start": "",
                        "url": href,
                        "location": "New York",
                        "source": "Meetup"
                    })

        except Exception as e:
            print(f"Error fetching Meetup events: {e}")

    return events


def format_event(event: Dict[str, Any]) -> str:
    """æ ¼å¼åŒ–å•ä¸ªæ´»åŠ¨ä¿¡æ¯"""
    name = event.get("name", "æœªçŸ¥æ´»åŠ¨")
    start = event.get("start", "")
    url = event.get("url", "")
    location = event.get("location", "New York")
    source = event.get("source", "")

    return f"""
ğŸ“… {name}
   ğŸ• {start if start else "æŸ¥çœ‹è¯¦æƒ…"}
   ğŸ“ {location}
   ğŸ”— {url}
   ğŸ“Œ æ¥æº: {source}
"""


def collect_all_events() -> List[Dict[str, Any]]:
    """æ”¶é›†æ‰€æœ‰æ¥æºçš„æ´»åŠ¨"""
    all_events = []
    seen_urls = set()

    print("Fetching from Luma...")
    luma_events = get_luma_events()
    print(f"  Found {len(luma_events)} Luma events")

    print("Fetching from Eventbrite...")
    eb_events = get_eventbrite_events()
    print(f"  Found {len(eb_events)} Eventbrite events")

    print("Fetching from Meetup...")
    meetup_events = get_meetup_events()
    print(f"  Found {len(meetup_events)} Meetup events")

    # åˆå¹¶å»é‡
    for event in luma_events + eb_events + meetup_events:
        url = event.get("url", "")
        if url and url not in seen_urls:
            seen_urls.add(url)
            all_events.append(event)

    return all_events


def generate_email_body(events: List[Dict[str, Any]]) -> str:
    """ç”Ÿæˆé‚®ä»¶å†…å®¹"""
    if not events:
        return "æœ¬å‘¨æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ´»åŠ¨ã€‚"

    # æŒ‰æ¥æºåˆ†ç»„
    by_source = {}
    for event in events:
        source = event.get("source", "Other")
        if source not in by_source:
            by_source[source] = []
        by_source[source].append(event)

    body = f"""
ğŸ—½ NYC Event Finder - æœ¬å‘¨æ´»åŠ¨æ¨è
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

æ‰¾åˆ° {len(events)} ä¸ªæ´»åŠ¨ï¼ˆæœªæ¥ {DAYS_AHEAD} å¤©ï¼‰

æœç´¢å…³é”®è¯ï¼š{', '.join(SEARCH_KEYWORDS)}
"""

    for source, source_events in by_source.items():
        body += f"\n\nâ”â”â” {source} ({len(source_events)} ä¸ªæ´»åŠ¨) â”â”â”"
        for event in source_events:
            body += format_event(event)

    body += """
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ç”± NYC Event Finder è‡ªåŠ¨ç”Ÿæˆ
"""
    return body


def send_email(subject: str, body: str):
    """å‘é€é‚®ä»¶"""
    import smtplib
    from email.mime.text import MIMEText
    from email.mime.multipart import MIMEMultipart

    smtp_server = os.environ.get("SMTP_SERVER", "smtp.gmail.com")
    smtp_port = int(os.environ.get("SMTP_PORT", "587"))
    smtp_user = os.environ.get("SMTP_USER", "")
    smtp_password = os.environ.get("SMTP_PASSWORD", "")
    recipient = os.environ.get("EMAIL_RECIPIENT", smtp_user)

    if not all([smtp_user, smtp_password]):
        print("Email credentials not configured. Printing to console instead:")
        print("=" * 50)
        print(f"Subject: {subject}")
        print("=" * 50)
        print(body)
        return

    msg = MIMEMultipart()
    msg["From"] = smtp_user
    msg["To"] = recipient
    msg["Subject"] = subject
    msg.attach(MIMEText(body, "plain", "utf-8"))

    try:
        with smtplib.SMTP(smtp_server, smtp_port) as server:
            server.starttls()
            server.login(smtp_user, smtp_password)
            server.send_message(msg)
        print(f"Email sent successfully to {recipient}")
    except Exception as e:
        print(f"Failed to send email: {e}")
        print("Email content:")
        print(body)


def main():
    print("ğŸ” NYC Event Finder starting...")
    print(f"Searching for events in {LOCATION}")
    print(f"Keywords: {SEARCH_KEYWORDS}")
    print()

    events = collect_all_events()
    print(f"\nFound {len(events)} unique events total")

    email_body = generate_email_body(events)
    subject = f"ğŸ—½ NYC Events - {datetime.now().strftime('%Y-%m-%d')}"

    send_email(subject, email_body)
    print("\nâœ… Done!")


if __name__ == "__main__":
    main()
